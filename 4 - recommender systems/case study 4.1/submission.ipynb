{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Case Study 4.1 - Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NAME              = Manuel Montoya Gamio\n",
    "# YOUR MITX PRO USERNAME = manuel-montoya-gamio\n",
    "# YOUR MITX PRO E-MAIL   = manuel.montoya@pucp.edu.pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these cells to install all the packages you need to complete the remainder of the case study. This may take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (20.1.1)\n",
      "Requirement already satisfied: surprise==0.1 in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (from surprise==0.1) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise->surprise==0.1) (1.17.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise->surprise==0.1) (1.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise->surprise==0.1) (1.12.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/manuel/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise->surprise==0.1) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install surprise==0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you must press **Kernel > Restart.** This allows the installation to take effect. Once you see the blue **Connected/Kernel ready** button in the top right, you are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn\n",
    "from surprise import Dataset, SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\n",
    "from surprise.model_selection import cross_validate, KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`**Dataset.load_builtin**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.Dataset.load_builtin) function to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x10dd8bf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to load the data...\n",
    "\n",
    "#loading dataset from surprise library\n",
    "surprise_data = Dataset.load_builtin('ml-100k')\n",
    "surprise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user movie  rating  timestamp\n",
       "0  196   242     3.0  881250949\n",
       "1  186   302     3.0  891717742\n",
       "2   22   377     1.0  878887116\n",
       "3  244    51     2.0  880606923\n",
       "4  166   346     1.0  886397596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = pd.DataFrame(surprise_data.raw_ratings, columns= [\"user\", \"movie\", \"rating\", \"timestamp\"])\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to get a sense of what the data looks like. Please create a histogram of all the ratings we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of registers: 100000\n",
      "Number of users: 943\n",
      "Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "# Number of registers of the dataset\n",
    "ratings = len(pd_data)\n",
    "users = pd_data['user'].nunique()\n",
    "movies = pd_data['movie'].nunique()\n",
    "\n",
    "print(f\"Number of registers: {ratings}\")\n",
    "print(f\"Number of users: {users}\")\n",
    "print(f\"Number of movies: {movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there are duplicate registers on the dataset for the pairs user - movie\n",
    "dropped = pd_data.drop_duplicates(subset = [\"user\", \"movie\"])\n",
    "len(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06304669364224531"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix sparcity\n",
    "ratings / (users * movies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating   user\n",
       "0     1.0   6110\n",
       "1     2.0  11370\n",
       "2     3.0  27145\n",
       "3     4.0  34174\n",
       "4     5.0  21201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating counts \n",
    "rating_counts = pd_data.get([\"user\", \"rating\"]).groupby(\"rating\", as_index = False).count()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rating histogram\n",
    "_ = matplotlib.pyplot.bar(rating_counts[\"rating\"], rating_counts[\"user\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;\">QUESTION 1: DATA ANALYSIS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the dataset. How many ratings are in the dataset? How would you describe the distribution of ratings? Is there anything else we should observe? Make sure the histogram is visible in the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consist of 100k ratings from 943 users to 1682 movies. It only has about 6% of the total possible ratings between the users and movies. There is a variate distribution over the 5 possible value of the ratings but there are more high ratings that lower ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.random_pred.NormalPredictor at 0x1a246ba050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model using NormalPredictor() class\n",
    "random_model = NormalPredictor()\n",
    "random_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5077  1.5184  1.5262  1.5279  1.5246  1.5209  0.0074  \n",
      "Fit time          0.10    0.10    0.10    0.10    0.10    0.10    0.00    \n",
      "Test time         0.15    0.10    0.14    0.10    0.10    0.12    0.02    \n"
     ]
    }
   ],
   "source": [
    "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
    "# See the cross_validate function that we have imported above\n",
    "# http://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.validation.cross_validate\n",
    "\n",
    "random_model_results = cross_validate(random_model, surprise_data, measures=['RMSE'], cv=5, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: User-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1a246b4dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model using KNNBasic() class\n",
    "# See the sim_options parameter to determine the user/item similarity calculation of the model\n",
    "# http://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration\n",
    "\n",
    "user_based_model = KNNBasic(sim_options={'user_based': True})\n",
    "user_based_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9741  0.9772  0.9767  0.9785  0.9854  0.9784  0.0038  \n",
      "Fit time          0.25    0.26    0.33    0.26    0.27    0.27    0.03    \n",
      "Test time         2.51    2.49    2.57    2.48    2.47    2.50    0.04    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "\n",
    "user_based_model_results = cross_validate(user_based_model, surprise_data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1a246a9b50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model using KNNBasic() class\n",
    "# Make sure you change the sim_options parameter from above\n",
    "\n",
    "item_based_model = KNNBasic(sim_options={'user_based': False})\n",
    "item_based_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9777  0.9726  0.9717  0.9724  0.9771  0.9743  0.0025  \n",
      "Fit time          0.40    0.42    0.41    0.41    0.44    0.42    0.02    \n",
      "Test time         2.83    2.81    2.89    3.00    2.95    2.90    0.07    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "item_based_model_results = cross_validate(item_based_model, surprise_data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;\">QUESTION 2: COLLABORATIVE FILTERING MODELS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the results from the user-user and item-item models. How do they compare to each other? How do they compare to our original \"random\" model? Can you provide any intuition as to why the results came out the way they did?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE of the trained models were the following\n",
    "\n",
    "* Random model: 1.5209\n",
    "* User based CF: 0.9784\n",
    "* Item based CF: **0.9743**\n",
    "\n",
    "The collaborative filtering models perform better than the random model reducing the RMSE in about 35% (1 - 0.9784/1.5209). The best model was the item based but the difference with the user based is not enough to draw a significant conclusion, especially since in some of the folds the user based get slightly better results. It makes sense that the CF models got better results since it's using a similarity function to make personalized recommendations and not treating the whole population as the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a24a77490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model using SVD() class\n",
    "svd_model = SVD()\n",
    "svd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9279  0.9400  0.9396  0.9406  0.9326  0.9361  0.0051  \n",
      "Fit time          3.75    3.77    3.77    3.87    3.77    3.79    0.04    \n",
      "Test time         0.11    0.18    0.11    0.10    0.16    0.13    0.03    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "svd_model_results = cross_validate(svd_model, surprise_data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;\">QUESTION 3: MATRIX FACTORIZATION MODEL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The matrix factorization model is different from the collaborative filtering models. Briefly describe this difference. Also, compare the RMSE again. Does it improve? Can you offer any reasoning as to why that might be?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with both collaborative filtering models, the RMSE is lower using matrix factorization\n",
    "\n",
    "* User based CF: 0.9784\n",
    "* Item based CF: 0.9743\n",
    "* Matrix Factorization: **0.9361**\n",
    "\n",
    "In the case of the CF models, the unknown ratings are estimated using the existing ratings of a neiborhood of similar users or items. To determine this similar users or items are compared using their vectors of ratings, but almost in all records, this vectors are disperse, which affect the performance of the model. On the other hand, the matrix factorization models find latent features that could be interpreted as the features of the movies and how much each user likes this features and getting the estimation of the rating by multipying this two vectors, which are not disperse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall @ `k`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to compute the precision and recall for 2 values of `k`: 5 and 10. We have provided some code here to help you do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function that takes in some predictions, a value of `k` and a threshold parameter. This code is adapted from [here](http://surprise.readthedocs.io/en/stable/FAQ.html?highlight=precision#how-to-compute-precision-k-and-recall-k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = dict()\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        current = user_est_true.get(uid, list())\n",
    "        current.append((est, true_r))\n",
    "        user_est_true[uid] = current\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the precision and recall at `k` = 5 and 10 for each of our 4 models. We use 5-fold cross validation again to average the results across the entire dataseat.\n",
    "\n",
    "Please note that this will take some time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;\">QUESTION 4: PRECISION/RECALL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the precision and recall, for each of the 4 models, at `k` = 5 and 10. This is 2 x 2 x 4 = 16 numerical values. Do you note anything interesting about these values? Anything differerent from the RMSE values you computed above?**\n",
    "\n",
    "Some code is required for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_for_model_k(data, model, model_name, k):\n",
    "    \"\"\"Calculates precision and recall for a model and a k value for the given data\"\"\"\n",
    "    \n",
    "    #the kfolder will return a generator with the 5 folds for the data\n",
    "    kfolder = KFold(n_splits = 5)\n",
    "    \n",
    "    mean_precision = 0\n",
    "    mean_recall = 0\n",
    "    \n",
    "    for data_train, data_test in kfolder.split(data):\n",
    "    \n",
    "        model.fit(data_train)\n",
    "        data_test_prediction = model.test(data_test, verbose = False)\n",
    "        \n",
    "        #calling the original function\n",
    "        fold_user_precisions, fold_user_recalls = precision_recall_at_k(data_test_prediction, k=k)\n",
    "        \n",
    "        #to get the fold average metrics we have to average the user presicion and recall\n",
    "        fold_precision = sum(fold_user_precisions.values()) / len(fold_user_precisions.values())\n",
    "        fold_recall = sum(fold_user_recalls.values()) / len(fold_user_recalls.values())\n",
    "        \n",
    "        mean_precision += fold_precision\n",
    "        mean_recall += fold_recall\n",
    "    \n",
    "    mean_precision = round(mean_precision / 5.0, 4)\n",
    "    mean_recall = round(mean_recall / 5.0, 4)\n",
    "    \n",
    "    return model_name, k, mean_precision, mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Use the function above to compute the 16 numerical values requested above\n",
    "# See the test() function to get the predictions input to the function\n",
    "# http://surprise.readthedocs.io/en/stable/algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.test\n",
    "\n",
    "#Dataframe to store the results\n",
    "pd_results = pd.DataFrame(columns = [\"model\", \"k\", \"precision\", \"recall\"])\n",
    "index = 0\n",
    "\n",
    "models = [random_model, user_based_model, item_based_model, svd_model]\n",
    "model_names = [\"random\", \"user based cf\", \"item based cf\", \"matrix factorization\"]\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for k in [5,10]:\n",
    "        pd_results.loc[index] = precision_recall_for_model_k(surprise_data, model, model_name, k)\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>k</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>item based cf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>item based cf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>matrix factorization</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>user based cf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>matrix factorization</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>0.5627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>user based cf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.5916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>random</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.4308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   k  precision  recall\n",
       "4         item based cf   5     0.8188  0.3904\n",
       "5         item based cf  10     0.7865  0.5344\n",
       "6  matrix factorization   5     0.7795  0.4291\n",
       "2         user based cf   5     0.7628  0.4568\n",
       "7  matrix factorization  10     0.7582  0.5627\n",
       "3         user based cf  10     0.7355  0.5916\n",
       "0                random   5     0.5924  0.3458\n",
       "1                random  10     0.5838  0.4308"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with best precision\n",
    "pd_results.sort_values(by = \"precision\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>k</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>user based cf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.5916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>matrix factorization</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>0.5627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>item based cf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>user based cf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>matrix factorization</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>item based cf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>random</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.3458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   k  precision  recall\n",
       "3         user based cf  10     0.7355  0.5916\n",
       "7  matrix factorization  10     0.7582  0.5627\n",
       "5         item based cf  10     0.7865  0.5344\n",
       "2         user based cf   5     0.7628  0.4568\n",
       "1                random  10     0.5838  0.4308\n",
       "6  matrix factorization   5     0.7795  0.4291\n",
       "4         item based cf   5     0.8188  0.3904\n",
       "0                random   5     0.5924  0.3458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with best recall\n",
    "pd_results.sort_values(by = \"recall\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the values are between 0 and 1 because they're ratios and not error metrics. The best possible value for each metric is 1.\n",
    "\n",
    "Again, the worst performing model is the random model and the collaborative filtering and matrix factorization models have similar performance with the item based performing specially well when evaluated with precision. \n",
    "\n",
    "The number of top k items that are recommended is also relevant since the results change for the same model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Top-`n` Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see what some of the actual movie ratings are for particular users, as outputs of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we define a helpful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = dict()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        current = top_n.get(uid, [])\n",
    "        current.append((iid, est))\n",
    "        top_n[uid] = current\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we call this function on each of our models, first training on **all** the data we have available, then predicting on the remaining, missing data. We use `n`=5 here, but you can pick any reasonable value of `n` you would like.\n",
    "\n",
    "This may take some time to compute, so be patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use [`**Dataset.build_full_trainset**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.DatasetAutoFolds.build_full_trainset) to get the full trainset from the data. Then call [`**Trainset.build_anti_testset**`](http://surprise.readthedocs.io/en/stable/trainset.html#surprise.Trainset.build_anti_testset) to get the testset out. Finally, `fit` on the trainset, `test` on the testset, then pass that result to our `get_top_n` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;\">QUESTION 5: TOP N PREDICTIONS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the top n predictions that you received make sense? What is the rating value (1-5) of these predictions? How could you use these predictions in the real-world if you were trying to build a generic content recommender system for a company?**\n",
    "\n",
    "Some code is required for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function and hints above to give the top-n predictions for a given user, for a reasonable value of n\n",
    "\n",
    "#Splitting the dataset in train - test\n",
    "surprise_train = surprise_data.build_full_trainset()\n",
    "surprise_test = surprise_train.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "random\n",
      "------------------------------------------------------------\n",
      "[('377', 5), ('346', 5), ('265', 5), ('234', 5), ('98', 5), ('193', 5), ('88', 5), ('241', 5), ('526', 5), ('135', 5)]\n",
      "user: 196        item: 377        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 346        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 265        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 234        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 98         r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 193        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 88         r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 241        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 526        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 135        r_ui = 3.53   est = 5.00   {'was_impossible': False}\n",
      "------------------------------------------------------------\n",
      "user based cf\n",
      "------------------------------------------------------------\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "[('1189', 5), ('1500', 5), ('814', 5), ('1536', 5), ('1599', 5), ('1653', 5), ('1467', 5), ('1122', 5), ('1201', 5), ('1293', 4.999999999999999)]\n",
      "user: 196        item: 1189       r_ui = 3.53   est = 5.00   {'actual_k': 3, 'was_impossible': False}\n",
      "user: 196        item: 1500       r_ui = 3.53   est = 5.00   {'actual_k': 2, 'was_impossible': False}\n",
      "user: 196        item: 814        r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 196        item: 1536       r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 196        item: 1293       r_ui = 3.53   est = 5.00   {'actual_k': 3, 'was_impossible': False}\n",
      "user: 196        item: 1599       r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 196        item: 1653       r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 196        item: 1467       r_ui = 3.53   est = 5.00   {'actual_k': 2, 'was_impossible': False}\n",
      "user: 196        item: 1122       r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 196        item: 1201       r_ui = 3.53   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n",
      "------------------------------------------------------------\n",
      "item based cf\n",
      "------------------------------------------------------------\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "[('1414', 4.666666666666667), ('1309', 4.5), ('1310', 4.5), ('1675', 4.333333333333333), ('1676', 4.3076923076923075), ('1536', 4.1875), ('1593', 4.182926829268292), ('1433', 4.116751269035532), ('1626', 4.095555555555556), ('600', 4.078028747433264)]\n",
      "user: 196        item: 1309       r_ui = 3.53   est = 4.50   {'actual_k': 4, 'was_impossible': False}\n",
      "user: 196        item: 1310       r_ui = 3.53   est = 4.50   {'actual_k': 4, 'was_impossible': False}\n",
      "user: 196        item: 1536       r_ui = 3.53   est = 4.19   {'actual_k': 15, 'was_impossible': False}\n",
      "user: 196        item: 600        r_ui = 3.53   est = 4.08   {'actual_k': 17, 'was_impossible': False}\n",
      "user: 196        item: 1593       r_ui = 3.53   est = 4.18   {'actual_k': 11, 'was_impossible': False}\n",
      "user: 196        item: 1414       r_ui = 3.53   est = 4.67   {'actual_k': 2, 'was_impossible': False}\n",
      "user: 196        item: 1433       r_ui = 3.53   est = 4.12   {'actual_k': 6, 'was_impossible': False}\n",
      "user: 196        item: 1676       r_ui = 3.53   est = 4.31   {'actual_k': 8, 'was_impossible': False}\n",
      "user: 196        item: 1675       r_ui = 3.53   est = 4.33   {'actual_k': 8, 'was_impossible': False}\n",
      "user: 196        item: 1626       r_ui = 3.53   est = 4.10   {'actual_k': 18, 'was_impossible': False}\n",
      "------------------------------------------------------------\n",
      "matrix factorization\n",
      "------------------------------------------------------------\n",
      "[('64', 4.568063738173376), ('318', 4.545676023713969), ('357', 4.527806661250128), ('313', 4.480744394691568), ('483', 4.401776890608114), ('134', 4.38019375350125), ('178', 4.347909527022508), ('59', 4.339626039480821), ('98', 4.335123969193202), ('603', 4.327122810347466)]\n",
      "user: 196        item: 98         r_ui = 3.53   est = 4.34   {'was_impossible': False}\n",
      "user: 196        item: 603        r_ui = 3.53   est = 4.33   {'was_impossible': False}\n",
      "user: 196        item: 483        r_ui = 3.53   est = 4.40   {'was_impossible': False}\n",
      "user: 196        item: 178        r_ui = 3.53   est = 4.35   {'was_impossible': False}\n",
      "user: 196        item: 318        r_ui = 3.53   est = 4.55   {'was_impossible': False}\n",
      "user: 196        item: 64         r_ui = 3.53   est = 4.57   {'was_impossible': False}\n",
      "user: 196        item: 357        r_ui = 3.53   est = 4.53   {'was_impossible': False}\n",
      "user: 196        item: 134        r_ui = 3.53   est = 4.38   {'was_impossible': False}\n",
      "user: 196        item: 59         r_ui = 3.53   est = 4.34   {'was_impossible': False}\n",
      "user: 196        item: 313        r_ui = 3.53   est = 4.48   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "models = [random_model, user_based_model, item_based_model, svd_model]\n",
    "model_names = [\"random\", \"user based cf\", \"item based cf\", \"matrix factorization\"]\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    \n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(model_name)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    \n",
    "    #fit and predict\n",
    "    model.fit(surprise_train)\n",
    "    predictions = model.test(surprise_test)\n",
    "    \n",
    "    top_n = get_top_n(predictions, n = 10)\n",
    "    \n",
    "    #get recommendations for the first user\n",
    "    user = list(top_n.keys())[0]\n",
    "    user_recommendations = top_n[user]\n",
    "    \n",
    "    #we print the top 10 recommendations for the user\n",
    "    print(user_recommendations)\n",
    "    \n",
    "    #we get the recommended movies \n",
    "    movies = [item[0] for item in user_recommendations]\n",
    "\n",
    "    #compare to actual ratings of the user for the recommended movies \n",
    "    complete_rows = [item for item in predictions if item[0] == user and item[1] in movies]\n",
    "    for row in complete_rows:\n",
    "        print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rating values are high and over the threshold, so they make sense with the implemented logic. The predominant value of the ratings in the recommendations is 5, which also makes sense since this are the top n recommendations.\n",
    "\n",
    "About how should this information can be used, this top n movies must be at the top of the screen in our platform (web or mobile app) since the probability that the user likes the movie is high. \n",
    "\n",
    "After we showed the user the top n items we should be listening on the implicit feedback from the user. How they interact with this top-n can help us calibrate better our model: if the user clicks or watches a movie, the user may like it, if they ignore it, it may not be a good movie for the user. We can use this active learning to improve the model constantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now, make sure you check out the **Conclusion** section of the [instruction manual](https://courses.edx.org/asset-v1:MITxPRO+DSx+2T2018+type@asset+block@4.1_instruction_manual.html) to wrap up this case study properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitxpro",
   "language": "python",
   "name": "mitxpro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
